{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "\n",
    "from datetime import datetime\n",
    "\n",
    "import os\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torchsummary import summary\n",
    "import time\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "torch.manual_seed(42)\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "transform = transforms.Compose(\n",
    "        [transforms.Resize((224, 224)),\n",
    "         transforms.Grayscale(num_output_channels=3),\n",
    "         transforms.ToTensor(),\n",
    "         transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n",
      "Training set has 6941 instances\n",
      "Validation set has 1736 instances\n"
     ]
    }
   ],
   "source": [
    "training_set = torchvision.datasets.Caltech101('/home/crueang/Chaks/AIOT/data', transform=transform, download=True)\n",
    "train_size = int(0.8 * len(training_set))\n",
    "test_size = len(training_set) - train_size\n",
    "training_set, validation_set = torch.utils.data.random_split(training_set, [train_size, test_size])\n",
    "\n",
    "training_loader = torch.utils.data.DataLoader(training_set, batch_size=16, shuffle=True)\n",
    "validation_loader = torch.utils.data.DataLoader(validation_set, batch_size=16, shuffle=False)\n",
    "\n",
    "print('Training set has {} instances'.format(len(training_set)))\n",
    "print('Validation set has {} instances'.format(len(validation_set)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_graph(history):\n",
    "    fig, (ax1, ax2) = plt.subplots(1, 2)\n",
    "    fig.set_figwidth(10)\n",
    "    fig.suptitle(\"Train vs Validation\")\n",
    "    ax1.plot(history[\"train_acc\"], label=\"Train\")\n",
    "    ax1.plot(history[\"validate_acc\"], label=\"Validation\")\n",
    "    ax1.legend()\n",
    "    ax1.set_title(\"Accuracy\")\n",
    "\n",
    "    ax2.plot(history[\"train_loss\"], label=\"Train\")\n",
    "    ax2.plot(history[\"validate_loss\"], label=\"Validation\")\n",
    "    ax2.legend()\n",
    "    ax2.set_title(\"Loss\")\n",
    "    fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ConvBlock(nn.Module):\n",
    "    def __init__(self, in_channels, out_channels, kernel_size, stride, padding, bias=True):\n",
    "        super(ConvBlock,self).__init__()\n",
    "        self.conv2d = nn.Conv2d(in_channels=in_channels, out_channels=out_channels,kernel_size=kernel_size,stride=stride, padding=padding, bias=bias)\n",
    "        self.batchnorm2d = nn.BatchNorm2d(out_channels)\n",
    "        self.relu = nn.ReLU()\n",
    "\n",
    "    def forward(self,x):\n",
    "        return self.relu(self.batchnorm2d(self.conv2d(x)))\n",
    "    \n",
    "class InceptionBlock(nn.Module):\n",
    "    def __init__(self, in_channels, out_1x1, red_3x3, out_3x3, red_5x5, out_5x5, out_1x1_pooling):\n",
    "        super(InceptionBlock,self).__init__()\n",
    "\n",
    "        self.branch1 = ConvBlock(in_channels,out_1x1,1,1,0)\n",
    "        self.branch2 = nn.Sequential(\n",
    "            ConvBlock(in_channels,red_3x3,1,1,0),\n",
    "            ConvBlock(red_3x3,out_3x3,3,1,1)\n",
    "        )\n",
    "        self.branch3 = nn.Sequential(\n",
    "            ConvBlock(in_channels,red_5x5,1,1,0),\n",
    "            ConvBlock(red_5x5,out_5x5,5,1,2)\n",
    "        )\n",
    "        self.branch4 = nn.Sequential(\n",
    "            nn.MaxPool2d(kernel_size=3,stride=1,padding=1),\n",
    "            ConvBlock(in_channels,out_1x1_pooling,1,1,0)\n",
    "        )\n",
    "\n",
    "    def forward(self,x):\n",
    "        return torch.cat([self.branch1(x), self.branch2(x), self.branch3(x), self.branch4(x)], dim=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "class InceptionNet(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(InceptionNet, self).__init__()\n",
    "        \n",
    "        self.conv1 = ConvBlock(3, 64, 7, 2, 3)\n",
    "        self.maxpool = nn.MaxPool2d(kernel_size=3, stride=2, padding=1)\n",
    "        \n",
    "        self.conv2 = ConvBlock(64, 192, 3, 1, 1)\n",
    "        \n",
    "        self.inception1 = InceptionBlock(192, 64, 96, 128, 16, 32, 32)\n",
    "        self.inception2 = InceptionBlock(256, 128, 128, 192, 32, 96, 64)\n",
    "        \n",
    "        self.inception3 = InceptionBlock(480, 192, 96, 208, 16, 48, 64)\n",
    "        self.inception4 = InceptionBlock(512, 160, 112, 224, 24, 64, 64)\n",
    "        \n",
    "        self.flatten = nn.Flatten()\n",
    "        self.dropout = nn.Dropout(p=0.4)\n",
    "        self.fc1 = nn.Linear(25088, 1024)\n",
    "        self.fc2 = nn.Linear(1024, 512)\n",
    "        self.fc3 = nn.Linear(512, 101)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        x = self.conv1(x)\n",
    "        x = self.maxpool(x)\n",
    "        x = self.conv2(x)\n",
    "        x = self.maxpool(x)\n",
    "        \n",
    "        x = self.inception1(x)\n",
    "        x = self.inception2(x)\n",
    "        x = self.maxpool(x)\n",
    "        \n",
    "        x = self.inception3(x)\n",
    "        x = self.inception4(x)\n",
    "        x = self.maxpool(x)\n",
    "        \n",
    "        x = self.dropout(x)\n",
    "        x = self.flatten(x)\n",
    "        x = self.fc1(x)\n",
    "        x = self.fc2(x)\n",
    "        x = self.fc3(x)\n",
    "        \n",
    "        return x\n",
    "    \n",
    "model = InceptionNet().to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [],
   "source": [
    "class InceptionV3Block(nn.Module):\n",
    "    def __init__(self, in_channels, out_1x1, out_1x1_pooling, red_1331_1x1, out_1x3_1x1, out_3x1_1x1, red_3x3, red1331_3x3, out1x3_3x3, out3x1_3x3):\n",
    "        super(InceptionV3Block,self).__init__()\n",
    "        \n",
    "        self.branch1 = ConvBlock(in_channels, out_1x1, 1, 1, 0)\n",
    "        self.branch2 = nn.Sequential(\n",
    "            nn.MaxPool2d(kernel_size=3, stride=1, padding=1),\n",
    "            ConvBlock(in_channels, out_1x1_pooling, 1, 1, 0)\n",
    "        )\n",
    "        self.branch3 = ConvBlock(in_channels, red_1331_1x1, 1, 1, 0)\n",
    "        self.branch3_1 = ConvBlock(red_1331_1x1, out_1x3_1x1, (1, 3), 1, (0, 1))\n",
    "        self.branch3_2 = ConvBlock(red_1331_1x1, out_3x1_1x1, (3, 1), 1, (1, 0))\n",
    "        self.branch4 = nn.Sequential(\n",
    "            ConvBlock(in_channels, red_3x3, 1, 1, 0),\n",
    "            ConvBlock(red_3x3, red1331_3x3, 3, 1, 1)\n",
    "        )\n",
    "        self.branch4_1 = ConvBlock(red1331_3x3, out1x3_3x3, (1, 3), 1, (0, 1))\n",
    "        self.branch4_2 = ConvBlock(red1331_3x3, out3x1_3x3, (3, 1), 1, (1, 0))\n",
    "    \n",
    "    def forward(self, x):\n",
    "        branch1 = self.branch1(x)\n",
    "        branch2 = self.branch2(x)\n",
    "        branch3 = self.branch3(x)\n",
    "        branch3_1 = self.branch3_1(branch3)\n",
    "        branch3_2 = self.branch3_2(branch3)\n",
    "        branch4 = self.branch4(x)\n",
    "        branch4_1 = self.branch4_1(branch4)\n",
    "        branch4_2 = self.branch4_2(branch4)\n",
    "        \n",
    "        return torch.cat([branch1, branch2, branch3_1, branch3_2, branch4_1, branch4_2], 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [],
   "source": [
    "class InceptionV3Net(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(InceptionV3Net, self).__init__()\n",
    "        \n",
    "        self.conv1 = ConvBlock(3, 64, 7, 2, 3)\n",
    "        self.maxpool1 = nn.MaxPool2d(kernel_size=3, stride=2, padding=1)\n",
    "        \n",
    "        self.conv2 = ConvBlock(64, 192, 3, 1, 1)\n",
    "        self.maxpool2 = nn.MaxPool2d(kernel_size=3, stride=2, padding=1)\n",
    "        \n",
    "        self.inception1 = InceptionV3Block(192, 64, 64, 128, 32, 32, 64, 128, 32, 32)\n",
    "        self.inception2 = InceptionV3Block(256, 32, 48, 128, 24, 24, 64, 192, 32, 32)\n",
    "        self.maxpool3 = nn.MaxPool2d(kernel_size=3, stride=2, padding=1)\n",
    "        \n",
    "        self.inception3 = InceptionV3Block(192, 192, 48, 96, 16, 16, 64, 128, 16, 16)\n",
    "        self.inception4 = InceptionV3Block(304, 192, 64, 128, 24, 24, 64, 128, 24, 24)\n",
    "        self.maxpool4 = nn.MaxPool2d(kernel_size=3, stride=2, padding=1)\n",
    "        \n",
    "        self.flatten = nn.Flatten()\n",
    "        self.dropout = nn.Dropout(p=0.4)\n",
    "        self.fc1 = nn.Linear(17248, 1024)\n",
    "        self.fc2 = nn.Linear(1024, 512)\n",
    "        self.fc3 = nn.Linear(512, 101)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        x = self.conv1(x)\n",
    "        x = self.maxpool1(x)\n",
    "        \n",
    "        x = self.conv2(x)\n",
    "        x = self.maxpool2(x)\n",
    "        \n",
    "        x = self.inception1(x)\n",
    "        x = self.inception2(x)\n",
    "        x = self.maxpool3(x)\n",
    "        \n",
    "        x = self.inception3(x)\n",
    "        x = self.inception4(x)\n",
    "        x = self.maxpool4(x)\n",
    "        \n",
    "        x = self.flatten(x)\n",
    "        x = self.dropout(x)\n",
    "        x = self.fc1(x)\n",
    "        x = self.fc2(x)\n",
    "        x = self.fc3(x)\n",
    "        \n",
    "        return x\n",
    "\n",
    "model = InceptionV3Net().to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------------------------------\n",
      "        Layer (type)               Output Shape         Param #\n",
      "================================================================\n",
      "            Conv2d-1         [-1, 64, 112, 112]           9,472\n",
      "       BatchNorm2d-2         [-1, 64, 112, 112]             128\n",
      "              ReLU-3         [-1, 64, 112, 112]               0\n",
      "         ConvBlock-4         [-1, 64, 112, 112]               0\n",
      "         MaxPool2d-5           [-1, 64, 56, 56]               0\n",
      "            Conv2d-6          [-1, 192, 56, 56]         110,784\n",
      "       BatchNorm2d-7          [-1, 192, 56, 56]             384\n",
      "              ReLU-8          [-1, 192, 56, 56]               0\n",
      "         ConvBlock-9          [-1, 192, 56, 56]               0\n",
      "        MaxPool2d-10          [-1, 192, 28, 28]               0\n",
      "           Conv2d-11           [-1, 64, 28, 28]          12,352\n",
      "      BatchNorm2d-12           [-1, 64, 28, 28]             128\n",
      "             ReLU-13           [-1, 64, 28, 28]               0\n",
      "        ConvBlock-14           [-1, 64, 28, 28]               0\n",
      "        MaxPool2d-15          [-1, 192, 28, 28]               0\n",
      "           Conv2d-16           [-1, 64, 28, 28]          12,352\n",
      "      BatchNorm2d-17           [-1, 64, 28, 28]             128\n",
      "             ReLU-18           [-1, 64, 28, 28]               0\n",
      "        ConvBlock-19           [-1, 64, 28, 28]               0\n",
      "           Conv2d-20          [-1, 128, 28, 28]          24,704\n",
      "      BatchNorm2d-21          [-1, 128, 28, 28]             256\n",
      "             ReLU-22          [-1, 128, 28, 28]               0\n",
      "        ConvBlock-23          [-1, 128, 28, 28]               0\n",
      "           Conv2d-24           [-1, 32, 28, 28]          12,320\n",
      "      BatchNorm2d-25           [-1, 32, 28, 28]              64\n",
      "             ReLU-26           [-1, 32, 28, 28]               0\n",
      "        ConvBlock-27           [-1, 32, 28, 28]               0\n",
      "           Conv2d-28           [-1, 32, 28, 28]          12,320\n",
      "      BatchNorm2d-29           [-1, 32, 28, 28]              64\n",
      "             ReLU-30           [-1, 32, 28, 28]               0\n",
      "        ConvBlock-31           [-1, 32, 28, 28]               0\n",
      "           Conv2d-32           [-1, 64, 28, 28]          12,352\n",
      "      BatchNorm2d-33           [-1, 64, 28, 28]             128\n",
      "             ReLU-34           [-1, 64, 28, 28]               0\n",
      "        ConvBlock-35           [-1, 64, 28, 28]               0\n",
      "           Conv2d-36          [-1, 128, 28, 28]          73,856\n",
      "      BatchNorm2d-37          [-1, 128, 28, 28]             256\n",
      "             ReLU-38          [-1, 128, 28, 28]               0\n",
      "        ConvBlock-39          [-1, 128, 28, 28]               0\n",
      "           Conv2d-40           [-1, 32, 28, 28]          12,320\n",
      "      BatchNorm2d-41           [-1, 32, 28, 28]              64\n",
      "             ReLU-42           [-1, 32, 28, 28]               0\n",
      "        ConvBlock-43           [-1, 32, 28, 28]               0\n",
      "           Conv2d-44           [-1, 32, 28, 28]          12,320\n",
      "      BatchNorm2d-45           [-1, 32, 28, 28]              64\n",
      "             ReLU-46           [-1, 32, 28, 28]               0\n",
      "        ConvBlock-47           [-1, 32, 28, 28]               0\n",
      " InceptionV3Block-48          [-1, 256, 28, 28]               0\n",
      "           Conv2d-49           [-1, 32, 28, 28]           8,224\n",
      "      BatchNorm2d-50           [-1, 32, 28, 28]              64\n",
      "             ReLU-51           [-1, 32, 28, 28]               0\n",
      "        ConvBlock-52           [-1, 32, 28, 28]               0\n",
      "        MaxPool2d-53          [-1, 256, 28, 28]               0\n",
      "           Conv2d-54           [-1, 48, 28, 28]          12,336\n",
      "      BatchNorm2d-55           [-1, 48, 28, 28]              96\n",
      "             ReLU-56           [-1, 48, 28, 28]               0\n",
      "        ConvBlock-57           [-1, 48, 28, 28]               0\n",
      "           Conv2d-58          [-1, 128, 28, 28]          32,896\n",
      "      BatchNorm2d-59          [-1, 128, 28, 28]             256\n",
      "             ReLU-60          [-1, 128, 28, 28]               0\n",
      "        ConvBlock-61          [-1, 128, 28, 28]               0\n",
      "           Conv2d-62           [-1, 24, 28, 28]           9,240\n",
      "      BatchNorm2d-63           [-1, 24, 28, 28]              48\n",
      "             ReLU-64           [-1, 24, 28, 28]               0\n",
      "        ConvBlock-65           [-1, 24, 28, 28]               0\n",
      "           Conv2d-66           [-1, 24, 28, 28]           9,240\n",
      "      BatchNorm2d-67           [-1, 24, 28, 28]              48\n",
      "             ReLU-68           [-1, 24, 28, 28]               0\n",
      "        ConvBlock-69           [-1, 24, 28, 28]               0\n",
      "           Conv2d-70           [-1, 64, 28, 28]          16,448\n",
      "      BatchNorm2d-71           [-1, 64, 28, 28]             128\n",
      "             ReLU-72           [-1, 64, 28, 28]               0\n",
      "        ConvBlock-73           [-1, 64, 28, 28]               0\n",
      "           Conv2d-74          [-1, 192, 28, 28]         110,784\n",
      "      BatchNorm2d-75          [-1, 192, 28, 28]             384\n",
      "             ReLU-76          [-1, 192, 28, 28]               0\n",
      "        ConvBlock-77          [-1, 192, 28, 28]               0\n",
      "           Conv2d-78           [-1, 32, 28, 28]          18,464\n",
      "      BatchNorm2d-79           [-1, 32, 28, 28]              64\n",
      "             ReLU-80           [-1, 32, 28, 28]               0\n",
      "        ConvBlock-81           [-1, 32, 28, 28]               0\n",
      "           Conv2d-82           [-1, 32, 28, 28]          18,464\n",
      "      BatchNorm2d-83           [-1, 32, 28, 28]              64\n",
      "             ReLU-84           [-1, 32, 28, 28]               0\n",
      "        ConvBlock-85           [-1, 32, 28, 28]               0\n",
      " InceptionV3Block-86          [-1, 192, 28, 28]               0\n",
      "        MaxPool2d-87          [-1, 192, 14, 14]               0\n",
      "           Conv2d-88          [-1, 192, 14, 14]          37,056\n",
      "      BatchNorm2d-89          [-1, 192, 14, 14]             384\n",
      "             ReLU-90          [-1, 192, 14, 14]               0\n",
      "        ConvBlock-91          [-1, 192, 14, 14]               0\n",
      "        MaxPool2d-92          [-1, 192, 14, 14]               0\n",
      "           Conv2d-93           [-1, 48, 14, 14]           9,264\n",
      "      BatchNorm2d-94           [-1, 48, 14, 14]              96\n",
      "             ReLU-95           [-1, 48, 14, 14]               0\n",
      "        ConvBlock-96           [-1, 48, 14, 14]               0\n",
      "           Conv2d-97           [-1, 96, 14, 14]          18,528\n",
      "      BatchNorm2d-98           [-1, 96, 14, 14]             192\n",
      "             ReLU-99           [-1, 96, 14, 14]               0\n",
      "       ConvBlock-100           [-1, 96, 14, 14]               0\n",
      "          Conv2d-101           [-1, 16, 14, 14]           4,624\n",
      "     BatchNorm2d-102           [-1, 16, 14, 14]              32\n",
      "            ReLU-103           [-1, 16, 14, 14]               0\n",
      "       ConvBlock-104           [-1, 16, 14, 14]               0\n",
      "          Conv2d-105           [-1, 16, 14, 14]           4,624\n",
      "     BatchNorm2d-106           [-1, 16, 14, 14]              32\n",
      "            ReLU-107           [-1, 16, 14, 14]               0\n",
      "       ConvBlock-108           [-1, 16, 14, 14]               0\n",
      "          Conv2d-109           [-1, 64, 14, 14]          12,352\n",
      "     BatchNorm2d-110           [-1, 64, 14, 14]             128\n",
      "            ReLU-111           [-1, 64, 14, 14]               0\n",
      "       ConvBlock-112           [-1, 64, 14, 14]               0\n",
      "          Conv2d-113          [-1, 128, 14, 14]          73,856\n",
      "     BatchNorm2d-114          [-1, 128, 14, 14]             256\n",
      "            ReLU-115          [-1, 128, 14, 14]               0\n",
      "       ConvBlock-116          [-1, 128, 14, 14]               0\n",
      "          Conv2d-117           [-1, 16, 14, 14]           6,160\n",
      "     BatchNorm2d-118           [-1, 16, 14, 14]              32\n",
      "            ReLU-119           [-1, 16, 14, 14]               0\n",
      "       ConvBlock-120           [-1, 16, 14, 14]               0\n",
      "          Conv2d-121           [-1, 16, 14, 14]           6,160\n",
      "     BatchNorm2d-122           [-1, 16, 14, 14]              32\n",
      "            ReLU-123           [-1, 16, 14, 14]               0\n",
      "       ConvBlock-124           [-1, 16, 14, 14]               0\n",
      "InceptionV3Block-125          [-1, 304, 14, 14]               0\n",
      "          Conv2d-126          [-1, 192, 14, 14]          58,560\n",
      "     BatchNorm2d-127          [-1, 192, 14, 14]             384\n",
      "            ReLU-128          [-1, 192, 14, 14]               0\n",
      "       ConvBlock-129          [-1, 192, 14, 14]               0\n",
      "       MaxPool2d-130          [-1, 304, 14, 14]               0\n",
      "          Conv2d-131           [-1, 64, 14, 14]          19,520\n",
      "     BatchNorm2d-132           [-1, 64, 14, 14]             128\n",
      "            ReLU-133           [-1, 64, 14, 14]               0\n",
      "       ConvBlock-134           [-1, 64, 14, 14]               0\n",
      "          Conv2d-135          [-1, 128, 14, 14]          39,040\n",
      "     BatchNorm2d-136          [-1, 128, 14, 14]             256\n",
      "            ReLU-137          [-1, 128, 14, 14]               0\n",
      "       ConvBlock-138          [-1, 128, 14, 14]               0\n",
      "          Conv2d-139           [-1, 24, 14, 14]           9,240\n",
      "     BatchNorm2d-140           [-1, 24, 14, 14]              48\n",
      "            ReLU-141           [-1, 24, 14, 14]               0\n",
      "       ConvBlock-142           [-1, 24, 14, 14]               0\n",
      "          Conv2d-143           [-1, 24, 14, 14]           9,240\n",
      "     BatchNorm2d-144           [-1, 24, 14, 14]              48\n",
      "            ReLU-145           [-1, 24, 14, 14]               0\n",
      "       ConvBlock-146           [-1, 24, 14, 14]               0\n",
      "          Conv2d-147           [-1, 64, 14, 14]          19,520\n",
      "     BatchNorm2d-148           [-1, 64, 14, 14]             128\n",
      "            ReLU-149           [-1, 64, 14, 14]               0\n",
      "       ConvBlock-150           [-1, 64, 14, 14]               0\n",
      "          Conv2d-151          [-1, 128, 14, 14]          73,856\n",
      "     BatchNorm2d-152          [-1, 128, 14, 14]             256\n",
      "            ReLU-153          [-1, 128, 14, 14]               0\n",
      "       ConvBlock-154          [-1, 128, 14, 14]               0\n",
      "          Conv2d-155           [-1, 24, 14, 14]           9,240\n",
      "     BatchNorm2d-156           [-1, 24, 14, 14]              48\n",
      "            ReLU-157           [-1, 24, 14, 14]               0\n",
      "       ConvBlock-158           [-1, 24, 14, 14]               0\n",
      "          Conv2d-159           [-1, 24, 14, 14]           9,240\n",
      "     BatchNorm2d-160           [-1, 24, 14, 14]              48\n",
      "            ReLU-161           [-1, 24, 14, 14]               0\n",
      "       ConvBlock-162           [-1, 24, 14, 14]               0\n",
      "InceptionV3Block-163          [-1, 352, 14, 14]               0\n",
      "       MaxPool2d-164            [-1, 352, 7, 7]               0\n",
      "         Flatten-165                [-1, 17248]               0\n",
      "         Dropout-166                [-1, 17248]               0\n",
      "          Linear-167                 [-1, 1024]      17,662,976\n",
      "          Linear-168                  [-1, 512]         524,800\n",
      "          Linear-169                  [-1, 101]          51,813\n",
      "================================================================\n",
      "Total params: 19,206,261\n",
      "Trainable params: 19,206,261\n",
      "Non-trainable params: 0\n",
      "----------------------------------------------------------------\n",
      "Input size (MB): 0.57\n",
      "Forward/backward pass size (MB): 88.45\n",
      "Params size (MB): 73.27\n",
      "Estimated Total Size (MB): 162.29\n",
      "----------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "summary(model, (3, 224, 224))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [],
   "source": [
    "EPOCHS = 10\n",
    "checkpoint_path = '/home/crueang/Chaks/AIOT/5_1_homework/checkpoint/inceptionV3/checkpoint_inceptionV3_pretrained/'\n",
    "training_logs = {\"train_loss\": [],  \"train_acc\": [], \"validate_loss\": [], \"validate_acc\": []}\n",
    "\n",
    "loss_fn = torch.nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr=0.001, momentum=0.9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "from train import train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epochs 1  train_loss: 1.88616 train_acc: 0.34280 validate_loss: 1.51023 validate_acc: 0.44050 \n",
      "--------------------------------------------------------------------------------\n",
      "Epochs 2  train_loss: 1.34675 train_acc: 0.50320 validate_loss: 1.34851 validate_acc: 0.51500 \n",
      "--------------------------------------------------------------------------------\n",
      "Epochs 3  train_loss: 1.15161 train_acc: 0.57460 validate_loss: 1.25132 validate_acc: 0.55063 \n",
      "--------------------------------------------------------------------------------\n",
      "Epochs 4  train_loss: 1.01342 train_acc: 0.63220 validate_loss: 1.12508 validate_acc: 0.60325 \n",
      "--------------------------------------------------------------------------------\n",
      "Epochs 5  train_loss: 0.89668 train_acc: 0.66980 validate_loss: 1.15028 validate_acc: 0.59825 \n",
      "--------------------------------------------------------------------------------\n",
      "Epochs 6  train_loss: 0.79438 train_acc: 0.71620 validate_loss: 1.24228 validate_acc: 0.58925 \n",
      "--------------------------------------------------------------------------------\n",
      "Epochs 7  train_loss: 0.73097 train_acc: 0.73740 validate_loss: 1.12968 validate_acc: 0.63725 \n",
      "--------------------------------------------------------------------------------\n",
      "Epochs 8  train_loss: 0.64682 train_acc: 0.76580 validate_loss: 1.43813 validate_acc: 0.56175 \n",
      "--------------------------------------------------------------------------------\n",
      "Epochs 9  train_loss: 0.56381 train_acc: 0.80140 validate_loss: 1.07378 validate_acc: 0.66325 \n",
      "--------------------------------------------------------------------------------\n",
      "Epochs 10 train_loss: 0.47067 train_acc: 0.82560 validate_loss: 1.55700 validate_acc: 0.60313 \n",
      "--------------------------------------------------------------------------------\n",
      "Time consumption for accelerated CUDA training (device:cuda): 168.3654453754425 sec\n"
     ]
    }
   ],
   "source": [
    "train(loss_fn, optimizer, model, training_logs, validation_loader, training_loader, EPOCHS, checkpoint_path=checkpoint_path, device=device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training set has 5000 instances\n",
      "Validation set has 8000 instances\n"
     ]
    }
   ],
   "source": [
    "transform = transforms.Compose(\n",
    "        [transforms.Resize((224, 224)),\n",
    "         transforms.Grayscale(num_output_channels=3),\n",
    "         transforms.ToTensor(),\n",
    "         transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))\n",
    "         ])\n",
    "\n",
    "training_set = torchvision.datasets.STL10('/home/crueang/Chaks/AIOT/data', split='train', transform=transform, download=False)\n",
    "validation_set = torchvision.datasets.STL10('/home/crueang/Chaks/AIOT/data', split='test', transform=transform, download=False)\n",
    "\n",
    "training_loader = torch.utils.data.DataLoader(training_set, batch_size=16, shuffle=True)\n",
    "validation_loader = torch.utils.data.DataLoader(validation_set, batch_size=16, shuffle=False)\n",
    "\n",
    "print('Training set has {} instances'.format(len(training_set)))\n",
    "print('Validation set has {} instances'.format(len(validation_set)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------------------------------\n",
      "        Layer (type)               Output Shape         Param #\n",
      "================================================================\n",
      "            Conv2d-1         [-1, 64, 112, 112]           9,472\n",
      "       BatchNorm2d-2         [-1, 64, 112, 112]             128\n",
      "              ReLU-3         [-1, 64, 112, 112]               0\n",
      "         ConvBlock-4         [-1, 64, 112, 112]               0\n",
      "         MaxPool2d-5           [-1, 64, 56, 56]               0\n",
      "            Conv2d-6          [-1, 192, 56, 56]         110,784\n",
      "       BatchNorm2d-7          [-1, 192, 56, 56]             384\n",
      "              ReLU-8          [-1, 192, 56, 56]               0\n",
      "         ConvBlock-9          [-1, 192, 56, 56]               0\n",
      "        MaxPool2d-10          [-1, 192, 28, 28]               0\n",
      "           Conv2d-11           [-1, 64, 28, 28]          12,352\n",
      "      BatchNorm2d-12           [-1, 64, 28, 28]             128\n",
      "             ReLU-13           [-1, 64, 28, 28]               0\n",
      "        ConvBlock-14           [-1, 64, 28, 28]               0\n",
      "        MaxPool2d-15          [-1, 192, 28, 28]               0\n",
      "           Conv2d-16           [-1, 64, 28, 28]          12,352\n",
      "      BatchNorm2d-17           [-1, 64, 28, 28]             128\n",
      "             ReLU-18           [-1, 64, 28, 28]               0\n",
      "        ConvBlock-19           [-1, 64, 28, 28]               0\n",
      "           Conv2d-20          [-1, 128, 28, 28]          24,704\n",
      "      BatchNorm2d-21          [-1, 128, 28, 28]             256\n",
      "             ReLU-22          [-1, 128, 28, 28]               0\n",
      "        ConvBlock-23          [-1, 128, 28, 28]               0\n",
      "           Conv2d-24           [-1, 32, 28, 28]          12,320\n",
      "      BatchNorm2d-25           [-1, 32, 28, 28]              64\n",
      "             ReLU-26           [-1, 32, 28, 28]               0\n",
      "        ConvBlock-27           [-1, 32, 28, 28]               0\n",
      "           Conv2d-28           [-1, 32, 28, 28]          12,320\n",
      "      BatchNorm2d-29           [-1, 32, 28, 28]              64\n",
      "             ReLU-30           [-1, 32, 28, 28]               0\n",
      "        ConvBlock-31           [-1, 32, 28, 28]               0\n",
      "           Conv2d-32           [-1, 64, 28, 28]          12,352\n",
      "      BatchNorm2d-33           [-1, 64, 28, 28]             128\n",
      "             ReLU-34           [-1, 64, 28, 28]               0\n",
      "        ConvBlock-35           [-1, 64, 28, 28]               0\n",
      "           Conv2d-36          [-1, 128, 28, 28]          73,856\n",
      "      BatchNorm2d-37          [-1, 128, 28, 28]             256\n",
      "             ReLU-38          [-1, 128, 28, 28]               0\n",
      "        ConvBlock-39          [-1, 128, 28, 28]               0\n",
      "           Conv2d-40           [-1, 32, 28, 28]          12,320\n",
      "      BatchNorm2d-41           [-1, 32, 28, 28]              64\n",
      "             ReLU-42           [-1, 32, 28, 28]               0\n",
      "        ConvBlock-43           [-1, 32, 28, 28]               0\n",
      "           Conv2d-44           [-1, 32, 28, 28]          12,320\n",
      "      BatchNorm2d-45           [-1, 32, 28, 28]              64\n",
      "             ReLU-46           [-1, 32, 28, 28]               0\n",
      "        ConvBlock-47           [-1, 32, 28, 28]               0\n",
      " InceptionV3Block-48          [-1, 256, 28, 28]               0\n",
      "           Conv2d-49           [-1, 32, 28, 28]           8,224\n",
      "      BatchNorm2d-50           [-1, 32, 28, 28]              64\n",
      "             ReLU-51           [-1, 32, 28, 28]               0\n",
      "        ConvBlock-52           [-1, 32, 28, 28]               0\n",
      "        MaxPool2d-53          [-1, 256, 28, 28]               0\n",
      "           Conv2d-54           [-1, 48, 28, 28]          12,336\n",
      "      BatchNorm2d-55           [-1, 48, 28, 28]              96\n",
      "             ReLU-56           [-1, 48, 28, 28]               0\n",
      "        ConvBlock-57           [-1, 48, 28, 28]               0\n",
      "           Conv2d-58          [-1, 128, 28, 28]          32,896\n",
      "      BatchNorm2d-59          [-1, 128, 28, 28]             256\n",
      "             ReLU-60          [-1, 128, 28, 28]               0\n",
      "        ConvBlock-61          [-1, 128, 28, 28]               0\n",
      "           Conv2d-62           [-1, 24, 28, 28]           9,240\n",
      "      BatchNorm2d-63           [-1, 24, 28, 28]              48\n",
      "             ReLU-64           [-1, 24, 28, 28]               0\n",
      "        ConvBlock-65           [-1, 24, 28, 28]               0\n",
      "           Conv2d-66           [-1, 24, 28, 28]           9,240\n",
      "      BatchNorm2d-67           [-1, 24, 28, 28]              48\n",
      "             ReLU-68           [-1, 24, 28, 28]               0\n",
      "        ConvBlock-69           [-1, 24, 28, 28]               0\n",
      "           Conv2d-70           [-1, 64, 28, 28]          16,448\n",
      "      BatchNorm2d-71           [-1, 64, 28, 28]             128\n",
      "             ReLU-72           [-1, 64, 28, 28]               0\n",
      "        ConvBlock-73           [-1, 64, 28, 28]               0\n",
      "           Conv2d-74          [-1, 192, 28, 28]         110,784\n",
      "      BatchNorm2d-75          [-1, 192, 28, 28]             384\n",
      "             ReLU-76          [-1, 192, 28, 28]               0\n",
      "        ConvBlock-77          [-1, 192, 28, 28]               0\n",
      "           Conv2d-78           [-1, 32, 28, 28]          18,464\n",
      "      BatchNorm2d-79           [-1, 32, 28, 28]              64\n",
      "             ReLU-80           [-1, 32, 28, 28]               0\n",
      "        ConvBlock-81           [-1, 32, 28, 28]               0\n",
      "           Conv2d-82           [-1, 32, 28, 28]          18,464\n",
      "      BatchNorm2d-83           [-1, 32, 28, 28]              64\n",
      "             ReLU-84           [-1, 32, 28, 28]               0\n",
      "        ConvBlock-85           [-1, 32, 28, 28]               0\n",
      " InceptionV3Block-86          [-1, 192, 28, 28]               0\n",
      "        MaxPool2d-87          [-1, 192, 14, 14]               0\n",
      "           Conv2d-88          [-1, 192, 14, 14]          37,056\n",
      "      BatchNorm2d-89          [-1, 192, 14, 14]             384\n",
      "             ReLU-90          [-1, 192, 14, 14]               0\n",
      "        ConvBlock-91          [-1, 192, 14, 14]               0\n",
      "        MaxPool2d-92          [-1, 192, 14, 14]               0\n",
      "           Conv2d-93           [-1, 48, 14, 14]           9,264\n",
      "      BatchNorm2d-94           [-1, 48, 14, 14]              96\n",
      "             ReLU-95           [-1, 48, 14, 14]               0\n",
      "        ConvBlock-96           [-1, 48, 14, 14]               0\n",
      "           Conv2d-97           [-1, 96, 14, 14]          18,528\n",
      "      BatchNorm2d-98           [-1, 96, 14, 14]             192\n",
      "             ReLU-99           [-1, 96, 14, 14]               0\n",
      "       ConvBlock-100           [-1, 96, 14, 14]               0\n",
      "          Conv2d-101           [-1, 16, 14, 14]           4,624\n",
      "     BatchNorm2d-102           [-1, 16, 14, 14]              32\n",
      "            ReLU-103           [-1, 16, 14, 14]               0\n",
      "       ConvBlock-104           [-1, 16, 14, 14]               0\n",
      "          Conv2d-105           [-1, 16, 14, 14]           4,624\n",
      "     BatchNorm2d-106           [-1, 16, 14, 14]              32\n",
      "            ReLU-107           [-1, 16, 14, 14]               0\n",
      "       ConvBlock-108           [-1, 16, 14, 14]               0\n",
      "          Conv2d-109           [-1, 64, 14, 14]          12,352\n",
      "     BatchNorm2d-110           [-1, 64, 14, 14]             128\n",
      "            ReLU-111           [-1, 64, 14, 14]               0\n",
      "       ConvBlock-112           [-1, 64, 14, 14]               0\n",
      "          Conv2d-113          [-1, 128, 14, 14]          73,856\n",
      "     BatchNorm2d-114          [-1, 128, 14, 14]             256\n",
      "            ReLU-115          [-1, 128, 14, 14]               0\n",
      "       ConvBlock-116          [-1, 128, 14, 14]               0\n",
      "          Conv2d-117           [-1, 16, 14, 14]           6,160\n",
      "     BatchNorm2d-118           [-1, 16, 14, 14]              32\n",
      "            ReLU-119           [-1, 16, 14, 14]               0\n",
      "       ConvBlock-120           [-1, 16, 14, 14]               0\n",
      "          Conv2d-121           [-1, 16, 14, 14]           6,160\n",
      "     BatchNorm2d-122           [-1, 16, 14, 14]              32\n",
      "            ReLU-123           [-1, 16, 14, 14]               0\n",
      "       ConvBlock-124           [-1, 16, 14, 14]               0\n",
      "InceptionV3Block-125          [-1, 304, 14, 14]               0\n",
      "          Conv2d-126          [-1, 192, 14, 14]          58,560\n",
      "     BatchNorm2d-127          [-1, 192, 14, 14]             384\n",
      "            ReLU-128          [-1, 192, 14, 14]               0\n",
      "       ConvBlock-129          [-1, 192, 14, 14]               0\n",
      "       MaxPool2d-130          [-1, 304, 14, 14]               0\n",
      "          Conv2d-131           [-1, 64, 14, 14]          19,520\n",
      "     BatchNorm2d-132           [-1, 64, 14, 14]             128\n",
      "            ReLU-133           [-1, 64, 14, 14]               0\n",
      "       ConvBlock-134           [-1, 64, 14, 14]               0\n",
      "          Conv2d-135          [-1, 128, 14, 14]          39,040\n",
      "     BatchNorm2d-136          [-1, 128, 14, 14]             256\n",
      "            ReLU-137          [-1, 128, 14, 14]               0\n",
      "       ConvBlock-138          [-1, 128, 14, 14]               0\n",
      "          Conv2d-139           [-1, 24, 14, 14]           9,240\n",
      "     BatchNorm2d-140           [-1, 24, 14, 14]              48\n",
      "            ReLU-141           [-1, 24, 14, 14]               0\n",
      "       ConvBlock-142           [-1, 24, 14, 14]               0\n",
      "          Conv2d-143           [-1, 24, 14, 14]           9,240\n",
      "     BatchNorm2d-144           [-1, 24, 14, 14]              48\n",
      "            ReLU-145           [-1, 24, 14, 14]               0\n",
      "       ConvBlock-146           [-1, 24, 14, 14]               0\n",
      "          Conv2d-147           [-1, 64, 14, 14]          19,520\n",
      "     BatchNorm2d-148           [-1, 64, 14, 14]             128\n",
      "            ReLU-149           [-1, 64, 14, 14]               0\n",
      "       ConvBlock-150           [-1, 64, 14, 14]               0\n",
      "          Conv2d-151          [-1, 128, 14, 14]          73,856\n",
      "     BatchNorm2d-152          [-1, 128, 14, 14]             256\n",
      "            ReLU-153          [-1, 128, 14, 14]               0\n",
      "       ConvBlock-154          [-1, 128, 14, 14]               0\n",
      "          Conv2d-155           [-1, 24, 14, 14]           9,240\n",
      "     BatchNorm2d-156           [-1, 24, 14, 14]              48\n",
      "            ReLU-157           [-1, 24, 14, 14]               0\n",
      "       ConvBlock-158           [-1, 24, 14, 14]               0\n",
      "          Conv2d-159           [-1, 24, 14, 14]           9,240\n",
      "     BatchNorm2d-160           [-1, 24, 14, 14]              48\n",
      "            ReLU-161           [-1, 24, 14, 14]               0\n",
      "       ConvBlock-162           [-1, 24, 14, 14]               0\n",
      "InceptionV3Block-163          [-1, 352, 14, 14]               0\n",
      "       MaxPool2d-164            [-1, 352, 7, 7]               0\n",
      "         Flatten-165                [-1, 17248]               0\n",
      "         Dropout-166                [-1, 17248]               0\n",
      "          Linear-167                 [-1, 1024]      17,662,976\n",
      "          Linear-168                  [-1, 512]         524,800\n",
      "          Linear-169                   [-1, 10]           5,130\n",
      "================================================================\n",
      "Total params: 19,159,578\n",
      "Trainable params: 19,159,578\n",
      "Non-trainable params: 0\n",
      "----------------------------------------------------------------\n",
      "Input size (MB): 0.57\n",
      "Forward/backward pass size (MB): 88.45\n",
      "Params size (MB): 73.09\n",
      "Estimated Total Size (MB): 162.12\n",
      "----------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "new_model_head = InceptionV3Net().to(device)\n",
    "checkpoint = torch.load('/home/crueang/Chaks/AIOT/5_1_homework/checkpoint/inceptionV3/checkpoint_inceptionV3_pretrained/best_model.pth', weights_only=True)\n",
    "new_model_head.load_state_dict(checkpoint, strict=False)\n",
    "new_model_head.fc3 = nn.Linear(512, 10).to(device)\n",
    "summary(new_model_head, (3, 224, 224))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {},
   "outputs": [],
   "source": [
    "EPOCHS = 5\n",
    "checkpoint_path = '/home/crueang/Chaks/AIOT/5_1_homework/checkpoint/inceptionV3/checkpoint_inceptionV3_resume/'\n",
    "training_logs = {\"train_loss\": [],  \"train_acc\": [], \"validate_loss\": [], \"validate_acc\": []}\n",
    "\n",
    "loss_fn = torch.nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.SGD(new_model_head.parameters(), lr=0.001, momentum=0.9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_checkpoint(model, optimizer, training_logs, checkpoint_path=None, device='cpu'):\n",
    "    epoch_number = 0\n",
    "    best_vloss = float('inf')\n",
    "    if checkpoint_path:\n",
    "        if os.path.exists(checkpoint_path + 'model.pth'):\n",
    "            model.load_state_dict(torch.load(checkpoint_path + 'model.pth', weights_only=True, map_location=device))\n",
    "\n",
    "        if os.path.exists(checkpoint_path + 'opt.pth'):\n",
    "            optimizer.load_state_dict(torch.load(checkpoint_path + 'opt.pth', weights_only=True, map_location=device))\n",
    "\n",
    "        if os.path.exists(checkpoint_path + 'training_logs.pth'):\n",
    "            training_logs = torch.load(checkpoint_path + 'training_logs.pth', weights_only=True)\n",
    "            epoch_number = len(training_logs['train_loss'])\n",
    "            best_vloss = min(training_logs['validate_loss'])\n",
    "    \n",
    "    for i in range(epoch_number):\n",
    "        print(f\"Epochs {i+1}\".ljust(10), end='')\n",
    "        for key in training_logs.keys():\n",
    "            print(f\"{key}: {training_logs[key][i]:.5f}\", end=\" \")\n",
    "        print()\n",
    "        print(\"-\"*80)\n",
    "\n",
    "    return training_logs, best_vloss, epoch_number\n",
    "\n",
    "def train(loss_fn, optimizer, model, training_logs, validation_loader, training_loader, EPOCHS, checkpoint_path=None, device='cpu'):\n",
    "    if checkpoint_path:\n",
    "        if not os.path.exists(checkpoint_path):\n",
    "            os.mkdir(checkpoint_path)\n",
    "        training_logs, best_vloss, epoch_number = load_checkpoint(model, optimizer, training_logs, checkpoint_path, device)\n",
    "    \n",
    "    t_0_accelerated = time.time()\n",
    "    for epoch in range(epoch_number, EPOCHS):\n",
    "        train_loss, train_correct = 0, 0\n",
    "        model.train(True)\n",
    "\n",
    "        for i, data in enumerate(training_loader):\n",
    "            inputs, labels = data[0].to(device), data[1].to(device)\n",
    "            optimizer.zero_grad()\n",
    "\n",
    "            outputs = model(inputs)\n",
    "\n",
    "            loss = loss_fn(outputs, labels)\n",
    "            loss.backward()\n",
    "\n",
    "            optimizer.step()\n",
    "\n",
    "            train_loss += loss.item()\n",
    "            train_correct += (outputs.argmax(1) == labels).float().sum().item()\n",
    "\n",
    "        training_logs[\"train_loss\"].append(train_loss / len(training_loader))\n",
    "        training_logs[\"train_acc\"].append(train_correct / len(training_loader.dataset))\n",
    "\n",
    "        model.eval()\n",
    "        valid_loss, valid_correct = 0, 0\n",
    "        with torch.no_grad():\n",
    "            for i, vdata in enumerate(validation_loader):\n",
    "                vinputs, vlabels = vdata[0].to(device), vdata[1].to(device)\n",
    "                voutputs = model(vinputs)\n",
    "\n",
    "                valid_loss += loss_fn(voutputs, vlabels).item()\n",
    "                valid_correct += (voutputs.argmax(1) == vlabels).float().sum().item()\n",
    "\n",
    "            training_logs[\"validate_loss\"].append(valid_loss / len(validation_loader))\n",
    "            training_logs[\"validate_acc\"].append(valid_correct / len(validation_loader.dataset))\n",
    "\n",
    "        print(f\"Epochs {epoch+1}\".ljust(10), end='')\n",
    "        for key in training_logs.keys():\n",
    "            print(f\"{key}: {training_logs[key][-1]:.5f}\", end=\" \")\n",
    "        print()\n",
    "        print(\"-\"*80)\n",
    "\n",
    "        if checkpoint_path:\n",
    "            torch.save(model.state_dict(), checkpoint_path + \"model.pth\")\n",
    "            torch.save(optimizer.state_dict(), checkpoint_path + \"opt.pth\")\n",
    "            torch.save(training_logs, checkpoint_path + 'training_logs.pth')\n",
    "            if best_vloss > valid_loss:\n",
    "               torch.save(model.state_dict(), checkpoint_path + \"best_model.pth\")\n",
    "               best_vloss = valid_loss\n",
    "\n",
    "    t_end_accelerated = time.time()-t_0_accelerated\n",
    "    print(f\"Time consumption for accelerated CUDA training (device:{device}): {t_end_accelerated} sec\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epochs 1  train_loss: 1.30982 train_acc: 0.51940 validate_loss: 1.35321 validate_acc: 0.53138 \n",
      "--------------------------------------------------------------------------------\n",
      "Epochs 2  train_loss: 1.02195 train_acc: 0.63200 validate_loss: 1.10962 validate_acc: 0.59550 \n",
      "--------------------------------------------------------------------------------\n",
      "Epochs 3  train_loss: 0.89961 train_acc: 0.67220 validate_loss: 1.46929 validate_acc: 0.50750 \n",
      "--------------------------------------------------------------------------------\n",
      "Epochs 4  train_loss: 0.81768 train_acc: 0.69940 validate_loss: 1.26175 validate_acc: 0.59075 \n",
      "--------------------------------------------------------------------------------\n",
      "Epochs 5  train_loss: 0.70224 train_acc: 0.74600 validate_loss: 1.08161 validate_acc: 0.62662 \n",
      "--------------------------------------------------------------------------------\n",
      "Time consumption for accelerated CUDA training (device:cuda): 148.68760561943054 sec\n"
     ]
    }
   ],
   "source": [
    "train(loss_fn, optimizer, new_model_head, training_logs, validation_loader, training_loader, EPOCHS, checkpoint_path=checkpoint_path, device=device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------------------------------\n",
      "        Layer (type)               Output Shape         Param #\n",
      "================================================================\n",
      "            Conv2d-1         [-1, 64, 112, 112]           9,472\n",
      "       BatchNorm2d-2         [-1, 64, 112, 112]             128\n",
      "              ReLU-3         [-1, 64, 112, 112]               0\n",
      "         ConvBlock-4         [-1, 64, 112, 112]               0\n",
      "         MaxPool2d-5           [-1, 64, 56, 56]               0\n",
      "            Conv2d-6          [-1, 192, 56, 56]         110,784\n",
      "       BatchNorm2d-7          [-1, 192, 56, 56]             384\n",
      "              ReLU-8          [-1, 192, 56, 56]               0\n",
      "         ConvBlock-9          [-1, 192, 56, 56]               0\n",
      "        MaxPool2d-10          [-1, 192, 28, 28]               0\n",
      "           Conv2d-11           [-1, 64, 28, 28]          12,352\n",
      "      BatchNorm2d-12           [-1, 64, 28, 28]             128\n",
      "             ReLU-13           [-1, 64, 28, 28]               0\n",
      "        ConvBlock-14           [-1, 64, 28, 28]               0\n",
      "        MaxPool2d-15          [-1, 192, 28, 28]               0\n",
      "           Conv2d-16           [-1, 64, 28, 28]          12,352\n",
      "      BatchNorm2d-17           [-1, 64, 28, 28]             128\n",
      "             ReLU-18           [-1, 64, 28, 28]               0\n",
      "        ConvBlock-19           [-1, 64, 28, 28]               0\n",
      "           Conv2d-20          [-1, 128, 28, 28]          24,704\n",
      "      BatchNorm2d-21          [-1, 128, 28, 28]             256\n",
      "             ReLU-22          [-1, 128, 28, 28]               0\n",
      "        ConvBlock-23          [-1, 128, 28, 28]               0\n",
      "           Conv2d-24           [-1, 32, 28, 28]          12,320\n",
      "      BatchNorm2d-25           [-1, 32, 28, 28]              64\n",
      "             ReLU-26           [-1, 32, 28, 28]               0\n",
      "        ConvBlock-27           [-1, 32, 28, 28]               0\n",
      "           Conv2d-28           [-1, 32, 28, 28]          12,320\n",
      "      BatchNorm2d-29           [-1, 32, 28, 28]              64\n",
      "             ReLU-30           [-1, 32, 28, 28]               0\n",
      "        ConvBlock-31           [-1, 32, 28, 28]               0\n",
      "           Conv2d-32           [-1, 64, 28, 28]          12,352\n",
      "      BatchNorm2d-33           [-1, 64, 28, 28]             128\n",
      "             ReLU-34           [-1, 64, 28, 28]               0\n",
      "        ConvBlock-35           [-1, 64, 28, 28]               0\n",
      "           Conv2d-36          [-1, 128, 28, 28]          73,856\n",
      "      BatchNorm2d-37          [-1, 128, 28, 28]             256\n",
      "             ReLU-38          [-1, 128, 28, 28]               0\n",
      "        ConvBlock-39          [-1, 128, 28, 28]               0\n",
      "           Conv2d-40           [-1, 32, 28, 28]          12,320\n",
      "      BatchNorm2d-41           [-1, 32, 28, 28]              64\n",
      "             ReLU-42           [-1, 32, 28, 28]               0\n",
      "        ConvBlock-43           [-1, 32, 28, 28]               0\n",
      "           Conv2d-44           [-1, 32, 28, 28]          12,320\n",
      "      BatchNorm2d-45           [-1, 32, 28, 28]              64\n",
      "             ReLU-46           [-1, 32, 28, 28]               0\n",
      "        ConvBlock-47           [-1, 32, 28, 28]               0\n",
      " InceptionV3Block-48          [-1, 256, 28, 28]               0\n",
      "           Conv2d-49           [-1, 32, 28, 28]           8,224\n",
      "      BatchNorm2d-50           [-1, 32, 28, 28]              64\n",
      "             ReLU-51           [-1, 32, 28, 28]               0\n",
      "        ConvBlock-52           [-1, 32, 28, 28]               0\n",
      "        MaxPool2d-53          [-1, 256, 28, 28]               0\n",
      "           Conv2d-54           [-1, 48, 28, 28]          12,336\n",
      "      BatchNorm2d-55           [-1, 48, 28, 28]              96\n",
      "             ReLU-56           [-1, 48, 28, 28]               0\n",
      "        ConvBlock-57           [-1, 48, 28, 28]               0\n",
      "           Conv2d-58          [-1, 128, 28, 28]          32,896\n",
      "      BatchNorm2d-59          [-1, 128, 28, 28]             256\n",
      "             ReLU-60          [-1, 128, 28, 28]               0\n",
      "        ConvBlock-61          [-1, 128, 28, 28]               0\n",
      "           Conv2d-62           [-1, 24, 28, 28]           9,240\n",
      "      BatchNorm2d-63           [-1, 24, 28, 28]              48\n",
      "             ReLU-64           [-1, 24, 28, 28]               0\n",
      "        ConvBlock-65           [-1, 24, 28, 28]               0\n",
      "           Conv2d-66           [-1, 24, 28, 28]           9,240\n",
      "      BatchNorm2d-67           [-1, 24, 28, 28]              48\n",
      "             ReLU-68           [-1, 24, 28, 28]               0\n",
      "        ConvBlock-69           [-1, 24, 28, 28]               0\n",
      "           Conv2d-70           [-1, 64, 28, 28]          16,448\n",
      "      BatchNorm2d-71           [-1, 64, 28, 28]             128\n",
      "             ReLU-72           [-1, 64, 28, 28]               0\n",
      "        ConvBlock-73           [-1, 64, 28, 28]               0\n",
      "           Conv2d-74          [-1, 192, 28, 28]         110,784\n",
      "      BatchNorm2d-75          [-1, 192, 28, 28]             384\n",
      "             ReLU-76          [-1, 192, 28, 28]               0\n",
      "        ConvBlock-77          [-1, 192, 28, 28]               0\n",
      "           Conv2d-78           [-1, 32, 28, 28]          18,464\n",
      "      BatchNorm2d-79           [-1, 32, 28, 28]              64\n",
      "             ReLU-80           [-1, 32, 28, 28]               0\n",
      "        ConvBlock-81           [-1, 32, 28, 28]               0\n",
      "           Conv2d-82           [-1, 32, 28, 28]          18,464\n",
      "      BatchNorm2d-83           [-1, 32, 28, 28]              64\n",
      "             ReLU-84           [-1, 32, 28, 28]               0\n",
      "        ConvBlock-85           [-1, 32, 28, 28]               0\n",
      " InceptionV3Block-86          [-1, 192, 28, 28]               0\n",
      "        MaxPool2d-87          [-1, 192, 14, 14]               0\n",
      "           Conv2d-88          [-1, 192, 14, 14]          37,056\n",
      "      BatchNorm2d-89          [-1, 192, 14, 14]             384\n",
      "             ReLU-90          [-1, 192, 14, 14]               0\n",
      "        ConvBlock-91          [-1, 192, 14, 14]               0\n",
      "        MaxPool2d-92          [-1, 192, 14, 14]               0\n",
      "           Conv2d-93           [-1, 48, 14, 14]           9,264\n",
      "      BatchNorm2d-94           [-1, 48, 14, 14]              96\n",
      "             ReLU-95           [-1, 48, 14, 14]               0\n",
      "        ConvBlock-96           [-1, 48, 14, 14]               0\n",
      "           Conv2d-97           [-1, 96, 14, 14]          18,528\n",
      "      BatchNorm2d-98           [-1, 96, 14, 14]             192\n",
      "             ReLU-99           [-1, 96, 14, 14]               0\n",
      "       ConvBlock-100           [-1, 96, 14, 14]               0\n",
      "          Conv2d-101           [-1, 16, 14, 14]           4,624\n",
      "     BatchNorm2d-102           [-1, 16, 14, 14]              32\n",
      "            ReLU-103           [-1, 16, 14, 14]               0\n",
      "       ConvBlock-104           [-1, 16, 14, 14]               0\n",
      "          Conv2d-105           [-1, 16, 14, 14]           4,624\n",
      "     BatchNorm2d-106           [-1, 16, 14, 14]              32\n",
      "            ReLU-107           [-1, 16, 14, 14]               0\n",
      "       ConvBlock-108           [-1, 16, 14, 14]               0\n",
      "          Conv2d-109           [-1, 64, 14, 14]          12,352\n",
      "     BatchNorm2d-110           [-1, 64, 14, 14]             128\n",
      "            ReLU-111           [-1, 64, 14, 14]               0\n",
      "       ConvBlock-112           [-1, 64, 14, 14]               0\n",
      "          Conv2d-113          [-1, 128, 14, 14]          73,856\n",
      "     BatchNorm2d-114          [-1, 128, 14, 14]             256\n",
      "            ReLU-115          [-1, 128, 14, 14]               0\n",
      "       ConvBlock-116          [-1, 128, 14, 14]               0\n",
      "          Conv2d-117           [-1, 16, 14, 14]           6,160\n",
      "     BatchNorm2d-118           [-1, 16, 14, 14]              32\n",
      "            ReLU-119           [-1, 16, 14, 14]               0\n",
      "       ConvBlock-120           [-1, 16, 14, 14]               0\n",
      "          Conv2d-121           [-1, 16, 14, 14]           6,160\n",
      "     BatchNorm2d-122           [-1, 16, 14, 14]              32\n",
      "            ReLU-123           [-1, 16, 14, 14]               0\n",
      "       ConvBlock-124           [-1, 16, 14, 14]               0\n",
      "InceptionV3Block-125          [-1, 304, 14, 14]               0\n",
      "          Conv2d-126          [-1, 192, 14, 14]          58,560\n",
      "     BatchNorm2d-127          [-1, 192, 14, 14]             384\n",
      "            ReLU-128          [-1, 192, 14, 14]               0\n",
      "       ConvBlock-129          [-1, 192, 14, 14]               0\n",
      "       MaxPool2d-130          [-1, 304, 14, 14]               0\n",
      "          Conv2d-131           [-1, 64, 14, 14]          19,520\n",
      "     BatchNorm2d-132           [-1, 64, 14, 14]             128\n",
      "            ReLU-133           [-1, 64, 14, 14]               0\n",
      "       ConvBlock-134           [-1, 64, 14, 14]               0\n",
      "          Conv2d-135          [-1, 128, 14, 14]          39,040\n",
      "     BatchNorm2d-136          [-1, 128, 14, 14]             256\n",
      "            ReLU-137          [-1, 128, 14, 14]               0\n",
      "       ConvBlock-138          [-1, 128, 14, 14]               0\n",
      "          Conv2d-139           [-1, 24, 14, 14]           9,240\n",
      "     BatchNorm2d-140           [-1, 24, 14, 14]              48\n",
      "            ReLU-141           [-1, 24, 14, 14]               0\n",
      "       ConvBlock-142           [-1, 24, 14, 14]               0\n",
      "          Conv2d-143           [-1, 24, 14, 14]           9,240\n",
      "     BatchNorm2d-144           [-1, 24, 14, 14]              48\n",
      "            ReLU-145           [-1, 24, 14, 14]               0\n",
      "       ConvBlock-146           [-1, 24, 14, 14]               0\n",
      "          Conv2d-147           [-1, 64, 14, 14]          19,520\n",
      "     BatchNorm2d-148           [-1, 64, 14, 14]             128\n",
      "            ReLU-149           [-1, 64, 14, 14]               0\n",
      "       ConvBlock-150           [-1, 64, 14, 14]               0\n",
      "          Conv2d-151          [-1, 128, 14, 14]          73,856\n",
      "     BatchNorm2d-152          [-1, 128, 14, 14]             256\n",
      "            ReLU-153          [-1, 128, 14, 14]               0\n",
      "       ConvBlock-154          [-1, 128, 14, 14]               0\n",
      "          Conv2d-155           [-1, 24, 14, 14]           9,240\n",
      "     BatchNorm2d-156           [-1, 24, 14, 14]              48\n",
      "            ReLU-157           [-1, 24, 14, 14]               0\n",
      "       ConvBlock-158           [-1, 24, 14, 14]               0\n",
      "          Conv2d-159           [-1, 24, 14, 14]           9,240\n",
      "     BatchNorm2d-160           [-1, 24, 14, 14]              48\n",
      "            ReLU-161           [-1, 24, 14, 14]               0\n",
      "       ConvBlock-162           [-1, 24, 14, 14]               0\n",
      "InceptionV3Block-163          [-1, 352, 14, 14]               0\n",
      "       MaxPool2d-164            [-1, 352, 7, 7]               0\n",
      "         Flatten-165                [-1, 17248]               0\n",
      "         Dropout-166                [-1, 17248]               0\n",
      "          Linear-167                 [-1, 1024]      17,662,976\n",
      "          Linear-168                  [-1, 512]         524,800\n",
      "          Linear-169                   [-1, 10]           5,130\n",
      "================================================================\n",
      "Total params: 19,159,578\n",
      "Trainable params: 5,130\n",
      "Non-trainable params: 19,154,448\n",
      "----------------------------------------------------------------\n",
      "Input size (MB): 0.57\n",
      "Forward/backward pass size (MB): 88.45\n",
      "Params size (MB): 73.09\n",
      "Estimated Total Size (MB): 162.12\n",
      "----------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "finetune = InceptionV3Net().to(device)\n",
    "checkpoint = torch.load('/home/crueang/Chaks/AIOT/5_1_homework/checkpoint/inceptionV3/checkpoint_inceptionV3_pretrained/best_model.pth', weights_only=True)\n",
    "finetune.load_state_dict(checkpoint, strict=False)\n",
    "for param in finetune.parameters():\n",
    "    param.requires_grad = False\n",
    "finetune.fc3 = nn.Linear(512, 10).to(device)\n",
    "summary(finetune, (3, 224, 224))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {},
   "outputs": [],
   "source": [
    "EPOCHS = 5\n",
    "checkpoint_path = '/home/crueang/Chaks/AIOT/5_1_homework/checkpoint/inceptionV3/checkpoint_inceptionV3_finetune/'\n",
    "training_logs = {\"train_loss\": [],  \"train_acc\": [], \"validate_loss\": [], \"validate_acc\": []}\n",
    "\n",
    "loss_fn = torch.nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.SGD(finetune.parameters(), lr=0.001, momentum=0.9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epochs 1  train_loss: 1.21402 train_acc: 0.55760 validate_loss: 1.17065 validate_acc: 0.57100 \n",
      "--------------------------------------------------------------------------------\n",
      "Epochs 2  train_loss: 1.05658 train_acc: 0.61400 validate_loss: 1.15870 validate_acc: 0.58013 \n",
      "--------------------------------------------------------------------------------\n",
      "Epochs 3  train_loss: 1.03112 train_acc: 0.62580 validate_loss: 1.16024 validate_acc: 0.57725 \n",
      "--------------------------------------------------------------------------------\n",
      "Epochs 4  train_loss: 1.00439 train_acc: 0.63940 validate_loss: 1.13167 validate_acc: 0.59637 \n",
      "--------------------------------------------------------------------------------\n",
      "Epochs 5  train_loss: 1.00078 train_acc: 0.63540 validate_loss: 1.16046 validate_acc: 0.58000 \n",
      "--------------------------------------------------------------------------------\n",
      "Time consumption for accelerated CUDA training (device:cuda): 118.77279782295227 sec\n"
     ]
    }
   ],
   "source": [
    "train(loss_fn, optimizer, finetune, training_logs, validation_loader, training_loader, EPOCHS, checkpoint_path=checkpoint_path, device=device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_labels_predictions(model, dataloader, device):\n",
    "    model.eval()  # Set the model to evaluation mode\n",
    "    all_labels = []\n",
    "    all_predictions = []\n",
    "\n",
    "    with torch.no_grad():  # Disable gradient computation\n",
    "        for inputs, labels in dataloader:\n",
    "            inputs = inputs.to(device)\n",
    "            labels = labels.to(device)\n",
    "\n",
    "            # Forward pass\n",
    "            outputs = model(inputs)\n",
    "\n",
    "            # Get the predicted class\n",
    "            _, predictions = torch.max(outputs, 1)\n",
    "\n",
    "            all_labels.extend(labels.cpu().numpy())\n",
    "            all_predictions.extend(predictions.cpu().numpy())\n",
    "\n",
    "    return all_labels, all_predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "UnpicklingError",
     "evalue": "Weights only load failed. Re-running `torch.load` with `weights_only` set to `False` will likely succeed, but it can result in arbitrary code execution. Do it only if you got the file from a trusted source.\n Please file an issue with the following so that we can make `weights_only=True` compatible with your use case: WeightsUnpickler error: Attempting to deserialize object on a CUDA device but torch.cuda.is_available() is False. If you are running on a CPU-only machine, please use torch.load with map_location=torch.device('cpu') to map your storages to the CPU.\n\nCheck the documentation of torch.load to learn more about types accepted by default with weights_only https://pytorch.org/docs/stable/generated/torch.load.html.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mUnpicklingError\u001b[0m                           Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[1], line 234\u001b[0m\n\u001b[1;32m    226\u001b[0m     plt\u001b[38;5;241m.\u001b[39msavefig(filename)\n\u001b[1;32m    228\u001b[0m \u001b[38;5;66;03m# Example usage\u001b[39;00m\n\u001b[1;32m    229\u001b[0m \u001b[38;5;66;03m# visualize(source_feature, target_feature, source_labels, target_labels, 'tsne_plot.png')\u001b[39;00m\n\u001b[1;32m    230\u001b[0m \n\u001b[1;32m    231\u001b[0m \n\u001b[1;32m    232\u001b[0m \n\u001b[1;32m    233\u001b[0m \u001b[38;5;66;03m###########################################################################################\u001b[39;00m\n\u001b[0;32m--> 234\u001b[0m checkpoint \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mload(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m/home/crueang/Chaks/AIOT/5_1_homework/checkpoint/inceptionV3/checkpoint_inceptionV3_finetune/best_model.pth\u001b[39m\u001b[38;5;124m'\u001b[39m, weights_only\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[1;32m    235\u001b[0m loaded_resume_model \u001b[38;5;241m=\u001b[39m InceptionV3Net()\u001b[38;5;241m.\u001b[39mto(device)\n\u001b[1;32m    236\u001b[0m loaded_resume_model\u001b[38;5;241m.\u001b[39mfc3 \u001b[38;5;241m=\u001b[39m nn\u001b[38;5;241m.\u001b[39mLinear(\u001b[38;5;241m512\u001b[39m, \u001b[38;5;241m10\u001b[39m)\u001b[38;5;241m.\u001b[39mto(device)\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/torch/serialization.py:1096\u001b[0m, in \u001b[0;36mload\u001b[0;34m(f, map_location, pickle_module, weights_only, mmap, **pickle_load_args)\u001b[0m\n\u001b[1;32m   1090\u001b[0m                 \u001b[38;5;28;01mreturn\u001b[39;00m _load(opened_zipfile,\n\u001b[1;32m   1091\u001b[0m                              map_location,\n\u001b[1;32m   1092\u001b[0m                              _weights_only_unpickler,\n\u001b[1;32m   1093\u001b[0m                              overall_storage\u001b[38;5;241m=\u001b[39moverall_storage,\n\u001b[1;32m   1094\u001b[0m                              \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mpickle_load_args)\n\u001b[1;32m   1095\u001b[0m             \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m-> 1096\u001b[0m                 \u001b[38;5;28;01mraise\u001b[39;00m pickle\u001b[38;5;241m.\u001b[39mUnpicklingError(_get_wo_message(\u001b[38;5;28mstr\u001b[39m(e))) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m   1097\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m _load(\n\u001b[1;32m   1098\u001b[0m             opened_zipfile,\n\u001b[1;32m   1099\u001b[0m             map_location,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1102\u001b[0m             \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mpickle_load_args,\n\u001b[1;32m   1103\u001b[0m         )\n\u001b[1;32m   1104\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m mmap:\n",
      "\u001b[0;31mUnpicklingError\u001b[0m: Weights only load failed. Re-running `torch.load` with `weights_only` set to `False` will likely succeed, but it can result in arbitrary code execution. Do it only if you got the file from a trusted source.\n Please file an issue with the following so that we can make `weights_only=True` compatible with your use case: WeightsUnpickler error: Attempting to deserialize object on a CUDA device but torch.cuda.is_available() is False. If you are running on a CPU-only machine, please use torch.load with map_location=torch.device('cpu') to map your storages to the CPU.\n\nCheck the documentation of torch.load to learn more about types accepted by default with weights_only https://pytorch.org/docs/stable/generated/torch.load.html."
     ]
    }
   ],
   "source": [
    "# https://github.com/fyse-nassar/Malware-Family-Classification/blob/master/Malware%20Opcode%20Ngrams%20Generator.ipynb\n",
    "# https://scikit-learn.org/0.18/auto_examples/model_selection/plot_confusion_matrix.html\n",
    "\n",
    "import itertools\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "def plot_confusion_matrix(cm, classes,\n",
    "                          normalize=False,\n",
    "                          title='Confusion matrix',\n",
    "                          cmap=plt.cm.Blues):\n",
    "    \"\"\"\n",
    "    This function prints and plots the confusion matrix.\n",
    "    given a sklearn confusion matrix (cm), make a nice plot\n",
    "\n",
    "    Arguments\n",
    "    ---------\n",
    "    cm:           confusion matrix from sklearn.metrics.confusion_matrix\n",
    "\n",
    "    target_names: given classification classes such as [0, 1, 2]\n",
    "                  the class names, for example: ['high', 'medium', 'low']\n",
    "\n",
    "    title:        the text to display at the top of the matrix\n",
    "\n",
    "    cmap:         the gradient of the values displayed from matplotlib.pyplot.cm\n",
    "                  see http://matplotlib.org/examples/color/colormaps_reference.html\n",
    "                  plt.get_cmap('jet') or plt.cm.Blues\n",
    "\n",
    "    Normalization can be applied by setting `normalize=True`.\n",
    "    normalize:    If False, plot the raw numbers\n",
    "                  If True, plot the proportions\n",
    "\n",
    "    Usage\n",
    "    -----\n",
    "    plot_confusion_matrix(cm           = cm,                  # confusion matrix created by\n",
    "                                                              # sklearn.metrics.confusion_matrix\n",
    "                          normalize    = True,                # show proportions\n",
    "                          target_names = y_labels_vals,       # list of names of the classes\n",
    "                          title        = best_estimator_name) # title of graph\n",
    "\n",
    "    Citiation\n",
    "    ---------\n",
    "    http://scikit-learn.org/stable/auto_examples/model_selection/plot_confusion_matrix.html\n",
    "\n",
    "    \"\"\"\n",
    "\n",
    "    plt.imshow(cm, interpolation='nearest', cmap=cmap)\n",
    "    plt.title(title)\n",
    "    plt.colorbar()\n",
    "    tick_marks = np.arange(len(classes))\n",
    "    #plt.xticks(tick_marks, classes, rotation=45)    #office-31\n",
    "    plt.xticks(tick_marks, classes, rotation=20, fontsize=12)    #office-home\n",
    "    plt.yticks(tick_marks, classes, fontsize=12)\n",
    "\n",
    "    if normalize==True:\n",
    "        cm = cm.astype('float') / (cm.sum(axis=1)[:, np.newaxis]+1)\n",
    "        #print(\"Normalized confusion matrix\")\n",
    "    #else:\n",
    "        #print('Confusion matrix, without normalization')\n",
    "\n",
    "    # print(cm)\n",
    "\n",
    "    formated = '.2f' if normalize==True else 'd'\n",
    "    #---manual---\n",
    "    thresh = cm.max() / 2.\n",
    "    #thresh > 0.5\n",
    "    for i, j in itertools.product(range(cm.shape[0]), range(cm.shape[1])):\n",
    "        plt.text(j, i, format(cm[i, j], formated),\n",
    "                 horizontalalignment=\"center\",\n",
    "                 color=\"white\" if cm[i, j] > thresh else \"black\")\n",
    "    #---sns---\n",
    "    #df_cm = pd.DataFrame(cm, classes, classes)\n",
    "    #sns.heatmap(df_cm, annot=True, fmt=formated, cmap=cmap)\n",
    "\n",
    "    plt.gcf().set_size_inches(8, 6)\n",
    "    plt.ylabel('Ground Truth')\n",
    "    plt.xlabel('Prediction')\n",
    "    plt.margins(2,2)\n",
    "    plt.tight_layout()\n",
    "\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "  Args: Collect feature\n",
    "  Ref: https://github.com/zhjscut/Bridging_UDA_SSL/blob/e0be6742f1203bb983261e3e1e57d34e1e03299d/common/utils/analysis/__init__.py#L7\n",
    "\"\"\"\n",
    "import torch\n",
    "from torch.utils.data import DataLoader\n",
    "import torch.nn as nn\n",
    "import tqdm\n",
    "import os.path as osp\n",
    "\n",
    "\n",
    "def collect_feature(data_loader: DataLoader, feature_extractor: nn.Module,\n",
    "                                   device: torch.device, max_num_features=None) -> torch.Tensor:\n",
    "    \"\"\"\n",
    "    Fetch data from `data_loader`, and then use `feature_extractor` to collect features\n",
    "    Args:\n",
    "        data_loader (torch.utils.data.DataLoader): Data loader.\n",
    "        feature_extractor (torch.nn.Module): A feature extractor.\n",
    "        device (torch.device)\n",
    "        max_num_features (int): The max number of features to return\n",
    "    Returns:\n",
    "        Features in shape (min(len(data_loader), max_num_features), :math:`|\\mathcal{F}|`).\n",
    "    \"\"\"\n",
    "    feature_extractor.eval()\n",
    "    all_features = []\n",
    "    all_labels = []\n",
    "    with torch.no_grad():\n",
    "        for i, (images, target) in enumerate(tqdm.tqdm(data_loader)):\n",
    "            images = images.to(device)\n",
    "            features = feature_extractor(images)\n",
    "            if isinstance(features, tuple):\n",
    "                # Check if it's a tuple (common when using certain pre-trained models)\n",
    "                # You may want to select the feature tensor you need from the tuple\n",
    "                # For example, if the feature tensor is the first element of the tuple:\n",
    "                feature_tensor = features[0]\n",
    "                feature_tensor = feature_tensor.to(device)  # Move the tensor to CPU\n",
    "            else:\n",
    "                feature_tensor = features.to(device)  # Move the tensor to CPU\n",
    "\n",
    "            all_features.append(feature_tensor)\n",
    "            all_labels.append(target)\n",
    "\n",
    "    return torch.cat(all_features, dim=0),\\\n",
    "        torch.cat(all_labels, dim=0) # Concatenate the list of feature tensors\n",
    "\n",
    "    #        all_features.append(features)\n",
    "    #        if max_num_features is not None and i >= max_num_features:\n",
    "    #            break\n",
    "    #return torch.cat(all_features, dim=0)\n",
    "\n",
    "\n",
    "# ref https://github.com/zhjscut/Bridging_UDA_SSL/blob/e0be6742f1203bb983261e3e1e57d34e1e03299d/common/utils/analysis/__init__.py#L7\n",
    "import torch\n",
    "import matplotlib\n",
    "\n",
    "matplotlib.use('Agg')\n",
    "from sklearn.manifold import TSNE\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.colors as col\n",
    "\n",
    "\n",
    "def visualize(source_feature: torch.Tensor, target_feature: torch.Tensor,\n",
    "              filename: str, source_color='r', target_color='b'):\n",
    "    \"\"\"\n",
    "    Visualize features from different domains using t-SNE.\n",
    "    Args:\n",
    "        source_feature (tensor): features from source domain in shape :math:`(minibatch, F)`\n",
    "        target_feature (tensor): features from target domain in shape :math:`(minibatch, F)`\n",
    "        filename (str): the file name to save t-SNE\n",
    "        source_color (str): the color of the source features. Default: 'r'\n",
    "        target_color (str): the color of the target features. Default: 'b'\n",
    "    \"\"\"\n",
    "    source_feature = source_feature.cpu().numpy()\n",
    "    target_feature = target_feature.cpu().numpy()\n",
    "    features = np.concatenate([source_feature, target_feature], axis=0)\n",
    "\n",
    "    # map features to 2-d using TSNE\n",
    "    X_tsne = TSNE(n_components=2, random_state=33).fit_transform(features)\n",
    "\n",
    "    # domain labels, 1 represents source while 0 represents target\n",
    "    domains = np.concatenate((np.ones(len(source_feature)), np.zeros(len(target_feature))))\n",
    "\n",
    "    # visualize using matplotlib\n",
    "    plt.figure(figsize=(10, 10))\n",
    "    plt.scatter(X_tsne[:, 0], X_tsne[:, 1], c=domains, cmap=col.ListedColormap([source_color, target_color]), s=20)  #default: s=2\n",
    "    plt.savefig(filename)\n",
    "\n",
    "import torch\n",
    "import numpy as np\n",
    "from sklearn.manifold import TSNE\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.colors as col\n",
    "\n",
    "\"\"\"\n",
    "  Arg: t-SNE for class clustering visualization\n",
    "\"\"\"\n",
    "\n",
    "def visualize_class_n_domain(source_feature: torch.Tensor, target_feature: torch.Tensor, source_labels: torch.Tensor, target_labels: torch.Tensor, filename: str, source_color='r', target_color='b'):\n",
    "    \"\"\"\n",
    "    Visualize features from different domains using t-SNE.\n",
    "    Args:\n",
    "        source_feature (tensor): features from source domain in shape :math:`(minibatch, F)`\n",
    "        target_feature (tensor): features from target domain in shape :math:`(minibatch, F)`\n",
    "        source_labels (tensor): class labels for source domain features\n",
    "        target_labels (tensor): class labels for target domain features\n",
    "        filename (str): the file name to save t-SNE\n",
    "        source_color (str): the color of the source features. Default: 'r'\n",
    "        target_color (str): the color of the target features. Default: 'b'\n",
    "    \"\"\"\n",
    "    source_feature = source_feature.cpu().numpy()\n",
    "    target_feature = target_feature.cpu().numpy()\n",
    "    source_labels = source_labels.cpu().numpy()\n",
    "    target_labels = target_labels.cpu().numpy()\n",
    "\n",
    "    # Combine features and labels\n",
    "    features = np.concatenate([source_feature, target_feature], axis=0)\n",
    "    labels = np.concatenate([source_labels, target_labels], axis=0)\n",
    "    domains = np.concatenate((np.ones(len(source_feature)), np.zeros(len(target_feature))))\n",
    "\n",
    "    # Map features to 2-D using t-SNE\n",
    "    X_tsne = TSNE(n_components=2, random_state=33).fit_transform(features)\n",
    "\n",
    "    # Visualize using matplotlib\n",
    "    plt.figure(figsize=(10, 10))\n",
    "\n",
    "    # Get unique class labels\n",
    "    unique_labels = np.unique(labels)\n",
    "\n",
    "    # Create a color map for classes\n",
    "    #cmap = plt.get_cmap('tab20', len(unique_labels))\n",
    "    cmap_s = plt.get_cmap('nipy_spectral', len(unique_labels))\n",
    "    cmap_r = plt.get_cmap('gist_rainbow', len(unique_labels))\n",
    "\n",
    "    # Plot data points for each class and domain\n",
    "    for label in unique_labels:\n",
    "        for domain in [0, 1]:\n",
    "            mask = (labels == label) & (domains == domain)\n",
    "            plt.scatter(X_tsne[mask, 0], X_tsne[mask, 1], c=cmap_s(label), s=10,\n",
    "                        #label=f\"Class {label}, Domain {domain}\",\n",
    "                        )\n",
    "\n",
    "    plt.legend()\n",
    "    plt.savefig(filename)\n",
    "\n",
    "# Example usage\n",
    "# visualize(source_feature, target_feature, source_labels, target_labels, 'tsne_plot.png')\n",
    "\n",
    "\n",
    "\n",
    "###########################################################################################\n",
    "checkpoint = torch.load('/home/crueang/Chaks/AIOT/5_1_homework/checkpoint/inceptionV3/checkpoint_inceptionV3_finetune/best_model.pth', weights_only=True)\n",
    "loaded_resume_model = InceptionV3Net().to(device)\n",
    "loaded_resume_model.fc3 = nn.Linear(512, 10).to(device)\n",
    "\n",
    "loaded_resume_model.load_state_dict(checkpoint, strict=False)\n",
    "\n",
    "\n",
    "source_feature, s_labels = collect_feature(validation_loader, loaded_resume_model, device)\n",
    "# target_feature, t_labels = collect_feature(target_dl, feature_extractor, device)\n",
    "\n",
    "# --- plot t-SNE\n",
    "if not os.path.exists('/home/crueang/Chaks/AIOT/5_1_homework/output'): os.mkdir('/home/crueang/Chaks/AIOT/5_1_homework/output')\n",
    "tSNE_filename = osp.join('/home/crueang/Chaks/AIOT/5_1_homework/output', 'W5-1__resumev3_tSNE.png')\n",
    "visualize_class_n_domain(source_feature, source_feature, s_labels, s_labels, tSNE_filename)    # single-domain multi-class rep\n",
    "# visualize_class_n_domain(source_feature, target_feature, s_labels, t_labels, tSNE_filename)    # two-domain multi-class rep\n",
    "print(\"Saving t-SNE to\", tSNE_filename)\n",
    "\n",
    "\n",
    "#--- Confusion matrix, F1-score, precision, recall, NMI/RI scores\n",
    "from sklearn.metrics import confusion_matrix, precision_recall_fscore_support, normalized_mutual_info_score, adjusted_rand_score#, f1_score\n",
    "# Class labels\n",
    "pos_labels = np.arange(10)\n",
    "lb_classes = ('0', '1', '2', '3', '4', '5', '6' ,'7', '8', '9')\n",
    "\n",
    "lb, prd = get_labels_predictions(loaded_resume_model, validation_loader, device)\n",
    "#---confusion matrix\n",
    "cm_target = confusion_matrix(y_true=lb,\n",
    "                            y_pred=prd,\n",
    "                            labels=pos_labels,\n",
    "                            normalize='true',\n",
    "                            )\n",
    "plt.figure()\n",
    "plt.rcParams.update({'font.size': 10, 'figure.figsize': (2,2)})\n",
    "plot_confusion_matrix(cm_target,\n",
    "                        classes=lb_classes,\n",
    "                        normalize=True,\n",
    "                        title='Conf. Mat. w.r.t. STL-10 ds',\n",
    "                        cmap=plt.cm.binary #Blues_r\n",
    "                        )    #Blues_r = off-white diagonal\n",
    "#---F1-score/Precision/Recall scores\n",
    "print(\"Precision/Recall/F-beta score:\", precision_recall_fscore_support(lb, prd, average='weighted', zero_division=0,\n",
    "                                          beta=1.0)) #labels=label_classes))\n",
    "#---Normalized Mutual Information (NMI) score\n",
    "nmi_score = normalized_mutual_info_score(labels_true=lb,\n",
    "                                        labels_pred=prd,\n",
    "                                        average_method='arithmetic',\n",
    "                                        )\n",
    "#---Rand Index (RI) score\n",
    "ri_score = adjusted_rand_score(labels_true=lb,\n",
    "                                labels_pred=prd,\n",
    "                                )\n",
    "print(f\"NMI score: {nmi_score}, RI score: {ri_score}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
